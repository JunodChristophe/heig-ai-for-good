{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import junodch_utils_read_img as utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import rasterio\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from umap.parametric_umap import ParametricUMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "### Fetch data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName = \"img/Sokoto/\"\n",
    "pathSatellite = folderName + \"Sentinel-2.tif\"\n",
    "#pathSatellite = folderName + \"Landsat-8.tif\"\n",
    "#pathNight = folderName + \"Night VIIRS_1.tif\"\n",
    "pathNight = folderName + \"lowres_night_1.tif\"\n",
    "pathValidation = folderName + \"Population GHSL_1.tif\"\n",
    "\n",
    "aoi = utils.getImgBorder(pathSatellite)\n",
    "\n",
    "# Fetch coords\n",
    "dataCoords, dataRadiance = utils.getTilesCoordsPerimeter(pathNight, validThreshold=1, area=aoi)\n",
    "\n",
    "trainMask = dataRadiance>25\n",
    "testMask = dataRadiance<2\n",
    "lightCoords = dataCoords[trainMask]\n",
    "darkCoords = dataCoords[testMask]\n",
    "\n",
    "print('Tiles:',dataCoords.shape[0])\n",
    "print('Light Tile:',lightCoords.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch images\n",
    "with rasterio.open(pathSatellite) as f:\n",
    "  trainData, _ = utils.getEachImgFromCoord(f, dataCoords[trainMask], True)\n",
    "trainData = utils.formatData(trainData, res=64, toFloat=True)\n",
    "print(trainData.shape)\n",
    "\n",
    "with rasterio.open(pathSatellite) as f:\n",
    "  testData, _ = utils.getEachImgFromCoord(f, dataCoords[testMask][:1000], True)\n",
    "testData = utils.formatData(testData, res=64, toFloat=True)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.shape\n",
    "trainDataFormated = tf.reshape(trainData, [trainData.shape[0], -1])\n",
    "print('shape',trainData.shape,trainDataFormated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=trainData.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "encoder = keras.Sequential([\n",
    "  layers.Conv2D(16,(3,3), 2, padding='same', activation='relu', input_shape=input_shape),\n",
    "  layers.Conv2D(16,(3,3), 2, padding='same', activation='relu'),\n",
    "  #layers.Conv2D(16,(3,3), 2, padding='same', activation='relu'),\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(units=2, name='encoder'),\n",
    "])\n",
    "decoder = keras.Sequential([\n",
    "  layers.Dense(np.prod((32,32,16)), activation='relu', input_shape=(2,)),\n",
    "  layers.Reshape(target_shape=(32,32,16)),\n",
    "  #layers.UpSampling2D((2,2)),\n",
    "  #layers.Conv2D(16,(3,3), padding='same', activation='relu'),\n",
    "  layers.UpSampling2D((2,2)),\n",
    "  layers.Conv2D(16,(3,3), padding='same', activation='relu'),\n",
    "  layers.UpSampling2D((2,2)),\n",
    "\n",
    "  layers.Conv2D(3, (3,3), padding='same', activation='sigmoid'),\n",
    "])\n",
    "lossFunction = keras.losses.MeanSquaredError() # l2\n",
    "\n",
    "embedder = ParametricUMAP(\n",
    "  encoder=encoder,\n",
    "  decoder=decoder,\n",
    "  autoencoder_loss=True,\n",
    "  #parametric_reconstruction_loss_fcn=lossFunction,\n",
    "  dims=input_shape,\n",
    "  parametric_reconstruction= True,\n",
    "  parametric_embedding=False,\n",
    "  #n_training_epochs = 1,\n",
    "  loss_report_frequency=40,\n",
    "  keras_fit_kwargs={\n",
    "    \"callbacks\": [TqdmCallback(verbose=1)],\n",
    "    \"verbose\": 0,\n",
    "  },\n",
    "  #reconstruction_validation=test,\n",
    "  verbose=False,\n",
    ")\n",
    "t = 2000\n",
    "#embedding = umap.UMAP(random_state=42).fit_transform(data_train[:t])\n",
    "embedding = embedder.fit_transform(trainDataFormated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(embedder._history['loss'])\n",
    "ax.set_ylabel('Cross Entropy')\n",
    "ax.set_xlabel('Epoch')\n",
    "embedding = encoder.predict(np.concatenate((testData, trainData), axis=0))\n",
    "fig, ax2 = plt.subplots( figsize=(10, 10))\n",
    "sc = ax2.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c= [0]*len(testData) + [1]*len(trainData),\n",
    "    cmap='rainbow',\n",
    "    s=100,\n",
    "    alpha=0.5,\n",
    "    rasterized=True,\n",
    ")\n",
    "ax2.axis('equal')\n",
    "ax2.set_title(\"UMAP in Tensorflow embedding\", fontsize=20)\n",
    "plt.colorbar(sc, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayAutoencoderUmapResults(autoencoder, dataInput, precision=0, isEmbedded=True):\n",
    "  MAX_ON_ROW = 20\n",
    "  total = dataInput.shape[0]\n",
    "  nRow = (dataInput.shape[0] // MAX_ON_ROW) + 1\n",
    "  nCol = MAX_ON_ROW if total > MAX_ON_ROW else total\n",
    "\n",
    "  # Display original\n",
    "  plt.figure(figsize=(30,nRow*2))\n",
    "  for i in range(0, total):\n",
    "    ax = plt.subplot(nRow, nCol, 1+i)\n",
    "    plt.imshow(dataInput[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  print(\"Original data:\",dataInput.shape)\n",
    "  plt.show()\n",
    "\n",
    "  # Display reconstruction\n",
    "  if isEmbedded:\n",
    "    decoded_imgs = autoencoder.inverse_transform(autoencoder.transform(dataInput))\n",
    "  else:\n",
    "    test = []\n",
    "    for d in dataInput:\n",
    "      test.append(tf.reshape(d, [-1]))\n",
    "    decoded_imgs = autoencoder.inverse_transform(autoencoder.transform(test))\n",
    "  plt.figure(figsize=(30,nRow*2))\n",
    "  print(\"Output data:\",decoded_imgs.shape)\n",
    "  for i in range(0, decoded_imgs.shape[0]):\n",
    "    ax = plt.subplot(nRow, nCol, 1+i)\n",
    "    if isEmbedded:\n",
    "      decoded_img = decoded_imgs[i]\n",
    "    else:\n",
    "      decoded_img = tf.reshape(decoded_imgs[i], [64,64,3])\n",
    "    plt.imshow(decoded_img)\n",
    "    score = lossFunction(dataInput[i], decoded_img)\n",
    "    plt.title(np.round(score,precision))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayAutoencoderUmapResults(embedder, trainData, precision=5, isEmbedded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(pathSatellite) as s:\n",
    "  validation, metaValid = utils.getEachImgFromCoord(s, test[0:1] + test[1104:1123]+ test[4000:4010]+ test[10000:10010], True)\n",
    "  #validation, metaValid = utils.getEachImgFromCoord(s, test[0:1] + test[1104:1123]+ test[2944:2964]+ test[4000:4020]+ test[5000:5020]+ test[10000:10020], True)\n",
    "\n",
    "displayAutoencoderUmapResults(embedder, utils.formatDataForAutoencoder(validation,res=64), precision=5, isEmbedded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.save('model/autoencoder_64_GEN8_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display area test\n",
    "with rasterio.open(pathSatellite) as s:\n",
    "  validationTest, metaValidTest = utils.getEachImgFromCoord(s, test[0:10] + test[368:378] + test[736:746] + test[1104:1114] + test[1472:1482], True)\n",
    "\n",
    "utils.displayTiles(validationTest, metaValidTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0877fde3bc78a9e7113f97fea145bff0c5aa8882703ee053f927d63ca7148c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
