{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import junodch_utils_read_img as utils\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "### Fetch data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName = \"img/Sokoto/\"\n",
    "pathSatellite = folderName + \"Sentinel-2.tif\"\n",
    "#pathNight = folderName + \"Night VIIRS_1.tif\"\n",
    "pathNight = folderName + \"lowres_night_1.tif\"\n",
    "pathValidation = folderName + \"Population GHSL_1.tif\"\n",
    "\n",
    "aoi = utils.getImgBorder(pathSatellite)\n",
    "\n",
    "# Fetch coords\n",
    "dataCoords, dataRadiance = utils.getTilesCoordsPerimeter(pathNight, area=aoi)\n",
    "\n",
    "trainMask = dataRadiance>25\n",
    "testMask = dataRadiance<=25\n",
    "train = dataCoords[trainMask]\n",
    "test = dataCoords[testMask]\n",
    "\n",
    "print('TrainingTile:',len(train))\n",
    "print('TestTile:',len(test))\n",
    "\n",
    "with rasterio.open(pathSatellite) as s:\n",
    "  data, meta = utils.getEachImgFromCoord(s, train, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0].shape)\n",
    "#print(meta[0])\n",
    "\n",
    "dataTrain_formated = utils.formatDataForAutoencoder(data, res=64, toFloat=True)     # !!\n",
    "print(dataTrain_formated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder\n",
    "input_shape = keras.Input(shape=dataTrain_formated.shape[1:])\n",
    "\n",
    "#optimizer = 'adam'\n",
    "optimizer = keras.optimizers.Adam(\n",
    "  learning_rate=0.001,\n",
    "  beta_1=0.9,\n",
    "  beta_2=0.999,\n",
    ")\n",
    "#lossFunction = keras.losses.MeanAbsoluteError() # L1\n",
    "lossFunction = keras.losses.MeanSquaredError() # l2\n",
    "#lossFunction = keras.losses.MeanSquaredLogarithmicError()\n",
    "#lossFunction = keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.SUM)\n",
    "activationFunction = 'relu'\n",
    "#activationFunction = lambda x: tf.keras.activations.relu(x, max_value=255)\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=3)\n",
    "\n",
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "  def vae_reconstruction_loss(y_true, y_predict):\n",
    "    reconstruction_loss_factor = 1000\n",
    "    reconstruction_loss = keras.backend.mean(keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "    return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "  def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "    kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "  def vae_kl_loss_metric(y_true, y_predict):\n",
    "    kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "  def vae_loss(y_true, y_predict):\n",
    "    reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "    kl_loss = vae_kl_loss(encoder_mu, encoder_log_variance)\n",
    "\n",
    "    loss = reconstruction_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "  return vae_loss\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "  def call(self, inputs):\n",
    "    mu, log_variance = inputs\n",
    "    epsilon = tf.keras.backend.random_normal(shape=tf.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    return mu + tf.keras.backend.exp(log_variance/2) * epsilon\n",
    "\n",
    "latent_space_dim = 8*8*16\n",
    "\n",
    "cnn = layers.Conv2D(16,(3,3), 2, padding='same', activation=activationFunction)(input_shape)\n",
    "#cnn = layers.Conv2D(16,(3,3), 2, padding='same', activation=activationFunction)(cnn)\n",
    "encoded = layers.Conv2D(32,(3,3), 2, padding='same', activation=activationFunction, name='encoder')(cnn)\n",
    "\n",
    "shape_before_flatten = keras.backend.int_shape(encoded)[1:]\n",
    "print(shape_before_flatten)\n",
    "\n",
    "cnn = layers.Flatten()(encoded)\n",
    "#cnn = layers.Dense(8*8*4, activation=activationFunction)(cnn)\n",
    "encoder_mu = layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(cnn)\n",
    "encoder_logvar = layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(cnn)\n",
    "\n",
    "encoder_output = Sampling()([encoder_mu, encoder_logvar])\n",
    "print(encoder_output.shape)\n",
    "\n",
    "\n",
    "#decoder_input = layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
    "decoder_dense_layer = layers.Dense(np.prod(shape_before_flatten), name=\"decoder_dense\")(encoder_output)\n",
    "decoder_reshape = layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer)\n",
    "\n",
    "cnn = layers.Conv2D(32,(3,3), padding='same', activation=activationFunction)(decoder_reshape)\n",
    "cnn = layers.UpSampling2D((2,2))(cnn)\n",
    "cnn = layers.Conv2D(16,(3,3), padding='same', activation=activationFunction)(cnn)\n",
    "cnn = layers.UpSampling2D((2,2))(cnn)\n",
    "decoder = layers.Conv2D(3, (3,3), padding='same', activation='sigmoid', name='decoder')(cnn)\n",
    "\n",
    "autoencoder = keras.Model(input_shape, decoder)\n",
    "lossFunction = loss_func(encoder_mu, encoder_logvar)\n",
    "autoencoder.compile(optimizer=optimizer, loss=lossFunction)\n",
    "#autoencoder.compile(optimizer=optimizer, loss=lossFunction)\n",
    "\n",
    "print('Encoder shape:',autoencoder.get_layer('encoder').output_shape)\n",
    "autoencoder.get_output_shape_at\n",
    "result = autoencoder.fit(dataTrain_formated, dataTrain_formated,\n",
    "                          epochs=50,\n",
    "                          batch_size=10,\n",
    "                          steps_per_epoch=10,\n",
    "                          shuffle=True,\n",
    "                          verbose=0,\n",
    "                          callbacks=[\n",
    "                            TqdmCallback(verbose=1), # Concise display progression\n",
    "                            earlyStop,\n",
    "                          ],\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'][:], label='Training')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayAutoEncoderResults(autoencoder, dataInput, showDetail=0, precision=0):\n",
    "  MAX_ON_ROW = 20\n",
    "  total = dataInput.shape[0]\n",
    "  nRow = (dataInput.shape[0] // MAX_ON_ROW) + 1\n",
    "  nCol = MAX_ON_ROW if total > MAX_ON_ROW else total\n",
    "  encoder = keras.Model(inputs=autoencoder.inputs, outputs=autoencoder.get_layer('encoder').output)\n",
    "\n",
    "  # Display original\n",
    "  plt.figure(figsize=(30,nRow*2))\n",
    "  for i in range(0, total):\n",
    "    ax = plt.subplot(nRow, nCol, 1+i)\n",
    "    plt.imshow(dataInput[i].eval(session=tf.compat.v1.Session()))       # !\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  print(\"Original data:\",dataInput.shape)\n",
    "  plt.show()\n",
    "\n",
    "  if showDetail == 1:\n",
    "    # Display encoded. The first MAX_ON_ROW only\n",
    "    encoded_imgs = encoder.predict(dataInput[:nCol], steps=1)       # !\n",
    "    displayImgCollection(encoded_imgs)\n",
    "  elif showDetail == 2:\n",
    "    layers = autoencoder.layers[0:len(autoencoder.layers)-1]\n",
    "    for l in layers:\n",
    "      if 'Conv2D' in l.__class__.__name__:\n",
    "        intermediateLayers = keras.Model(inputs=autoencoder.inputs, outputs=l.output)\n",
    "        encoded_imgs = intermediateLayers.predict(dataInput[:nCol], steps=1)       # !\n",
    "        displayImgCollection(encoded_imgs)\n",
    "  \n",
    "  # Display reconstruction\n",
    "  decoded_imgs = autoencoder.predict(dataInput, steps=1)       # !\n",
    "  plt.figure(figsize=(30,nRow*2))\n",
    "  for i in range(0, decoded_imgs.shape[0]):\n",
    "    ax = plt.subplot(nRow, nCol, 1+i)\n",
    "    #score = autoencoder.loss(dataInput[i], decoded_imgs[i])\n",
    "    score = lossFunction(dataInput[i], decoded_imgs[i])\n",
    "    plt.title(np.round(score.eval(session=tf.compat.v1.Session()),precision))\n",
    "    #plt.imshow(decoded_imgs[i].astype('uint8'))\n",
    "    plt.imshow(decoded_imgs[i].astype('float32')) # TODO CHANGE !!!\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  print(\"Output data:\",decoded_imgs.shape)\n",
    "  plt.show()\n",
    "\n",
    "def displayImgCollection(imgs):\n",
    "  grid = gridspec.GridSpec(1, imgs.shape[0])\n",
    "  plt.figure(figsize=(30,imgs[0].T.shape[0]/8))\n",
    "  for i in range(0, imgs.shape[0]):\n",
    "    nCol = imgs[i].T.shape[0]\n",
    "    nRow = 1\n",
    "    while nCol > 8:\n",
    "      nCol = math.ceil(nCol/2)\n",
    "      nRow *= 2\n",
    "    cell = gridspec.GridSpecFromSubplotSpec(int(nRow), int(nCol), subplot_spec=grid[i], wspace=0.1, hspace=0.1)\n",
    "    for index, img in enumerate(imgs[i].T):\n",
    "      ax = plt.subplot(cell[index])\n",
    "      plt.imshow(img.eval(session=tf.compat.v1.Session()))      # !\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)\n",
    "  print(\"Data:\",imgs.shape)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataInput = dataTrain_formated[dataTrain_formated.shape[0]-40:]\n",
    "\n",
    "displayAutoEncoderResults(autoencoder, dataInput, showDetail=0, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(pathSatellite) as s:\n",
    "  validation, metaValid = utils.getEachImgFromCoord(s, test[0:1] + test[1104:1123]+ test[4000:4010]+ test[10000:10010], True)\n",
    "  #validation, metaValid = utils.getEachImgFromCoord(s, test[0:1] + test[1104:1123]+ test[2944:2964]+ test[4000:4020]+ test[5000:5020]+ test[10000:10020], True)\n",
    "\n",
    "displayAutoEncoderResults(autoencoder, utils.formatDataForAutoencoder(validation,res=64, toFloat=True), showDetail=0, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('model/autoencoder_64_GEN7_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display area test\n",
    "with rasterio.open(pathSatellite) as s:\n",
    "  validationTest, metaValidTest = utils.getEachImgFromCoord(s, test[0:10] + test[368:378] + test[736:746] + test[1104:1114] + test[1472:1482], True)\n",
    "\n",
    "utils.displayTiles(validationTest, metaValidTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0877fde3bc78a9e7113f97fea145bff0c5aa8882703ee053f927d63ca7148c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
