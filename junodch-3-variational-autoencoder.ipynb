{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Variational Autoencoder\n",
    "Train a variational autoencoder then test it with a view samples to see the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as matPlt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import junodch_utils_read_img as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "### Fetch data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName = \"img/Sokoto/\"\n",
    "pathSatellite = folderName + \"Sentinel-2.tif\"\n",
    "pathNight = folderName + \"Night_VIIRS.tif\"\n",
    "pathValidation = folderName + \"Population_GHSL.tif\"\n",
    "\n",
    "aoi = utils.getImgBorder(pathSatellite)\n",
    "\n",
    "# Fetch coords\n",
    "dataCoords, dataRadiance = utils.getTilesCoordsPerimeter(pathNight, area=aoi)\n",
    "\n",
    "trainMask = dataRadiance>0.2\n",
    "lightCoords = dataCoords[trainMask]\n",
    "\n",
    "print('Tiles:',dataCoords.shape[0])\n",
    "print('Light Tile:',lightCoords.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(pathSatellite) as f:\n",
    "  trainData, _ = utils.getEachImgFromCoord(f, lightCoords, True)\n",
    "trainData = utils.formatData(trainData, res=64, toFloat=True)\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder\n",
    "input_shape = keras.Input(shape=trainData.shape[1:])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(\n",
    "  learning_rate=0.001,\n",
    "  beta_1=0.9,\n",
    "  beta_2=0.999,\n",
    ")\n",
    "\n",
    "lossFunction = keras.losses.MeanSquaredError() # l2\n",
    "\n",
    "activationFunction = 'relu'\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=3)\n",
    "\n",
    "'''\n",
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "  def vae_reconstruction_loss(y_true, y_predict):\n",
    "    reconstruction_loss_factor = 1000\n",
    "    reconstruction_loss = keras.backend.mean(keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "    return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "  def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "    kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "  def vae_kl_loss_metric(y_true, y_predict):\n",
    "    kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "  def vae_loss(y_true, y_predict):\n",
    "    reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "    kl_loss = vae_kl_loss(encoder_mu, encoder_log_variance)\n",
    "\n",
    "    loss = reconstruction_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "  return vae_loss\n",
    "  \n",
    "lossFunction = loss_func(encoder_mu, encoder_logvar)\n",
    "'''\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "  def call(self, inputs):\n",
    "    mu, log_variance = inputs\n",
    "    epsilon = tf.keras.backend.random_normal(shape=tf.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    return mu + tf.keras.backend.exp(log_variance/2) * epsilon\n",
    "\n",
    "latent_space_dim = 8*8*16\n",
    "\n",
    "# mu encoder\n",
    "cnn = layers.Conv2D(32,(3,3), 2, padding='same', activation=activationFunction)(input_shape)\n",
    "cnn = layers.Conv2D(32,(3,3), 2, padding='same', activation=activationFunction)(cnn)\n",
    "encoded = layers.Conv2D(16,(3,3), 2, padding='same', activation=activationFunction, name='displayable_encoder')(cnn)\n",
    "\n",
    "shape_before_flatten = keras.backend.int_shape(encoded)[1:]\n",
    "\n",
    "encoder_mu = layers.Flatten(name='encoder')(encoded)\n",
    "\n",
    "# logvar encoder\n",
    "cnn = layers.Conv2D(32,(3,3), 2, padding='same', activation=activationFunction)(input_shape)\n",
    "cnn = layers.Conv2D(32,(3,3), 2, padding='same', activation=activationFunction)(cnn)\n",
    "encoded = layers.Conv2D(16,(3,3), 2, padding='same', activation=activationFunction)(cnn)\n",
    "encoder_logvar = layers.Flatten()(encoded)\n",
    "\n",
    "encoder_output = Sampling()([encoder_mu, encoder_logvar])\n",
    "\n",
    "decoder_dense_layer = layers.Dense(np.prod(shape_before_flatten), name=\"decoder_dense\")(encoder_output)\n",
    "decoder_reshape = layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer)\n",
    "\n",
    "cnn = layers.Conv2DTranspose(32,(3,3),2, padding='same', activation=activationFunction)(decoder_reshape)\n",
    "cnn = layers.Conv2DTranspose(32,(3,3),2, padding='same', activation=activationFunction)(cnn)\n",
    "decoder = layers.Conv2DTranspose(3, (3,3),2, padding='same', activation='sigmoid', name='decoder')(cnn)\n",
    "\n",
    "autoencoder = keras.Model(input_shape, decoder)\n",
    "\n",
    "autoencoder.compile(optimizer=optimizer, loss=lossFunction)\n",
    "\n",
    "print('Encoder shape:',autoencoder.get_layer('encoder').output_shape)\n",
    "\n",
    "result = autoencoder.fit(trainData, trainData,\n",
    "                          epochs=5,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          verbose=0,\n",
    "                          callbacks=[\n",
    "                            TqdmCallback(verbose=1), # Concise display progression\n",
    "                            earlyStop,\n",
    "                          ],\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPlt.plot(result.history['loss'][:], label='Training')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test display some tiles\")\n",
    "\n",
    "indexesTest = [*np.argwhere(trainMask)[100:600:25].flatten(), *range(0,100000,5000)]\n",
    "\n",
    "with rasterio.open(pathSatellite) as f:\n",
    "  dataTest, _ = utils.coordsToImgsFormated(f, dataCoords[indexesTest], res=64)\n",
    "\n",
    "utils.displayAutoEncoderResults(autoencoder, dataTest, showDetail=0, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('model/var_autoencoder_64px_encoder_1024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0877fde3bc78a9e7113f97fea145bff0c5aa8882703ee053f927d63ca7148c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
